{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, TimeoutException, ElementNotInteractableException, ElementClickInterceptedException\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\SAGAR KADAM\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nykaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Headphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of Nykaa\n",
    "url = \"https://www.nykaa.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_class_name(\"css-1p0hsio\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('Headphones')                                   # sending user input to search bar\n",
    "search_bar.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links1=[]\n",
    "driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(2)\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"product-list-box card desktop-cart\"]/a'):\n",
    "        links1.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links1.append(\"-\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* smart watches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of nykaa\n",
    "url = \"https://www.nykaa.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_class_name(\"css-1p0hsio\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('smart watches')                                   # sending user input to search bar\n",
    "search_bar.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(2)\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"product-list-box card desktop-cart\"]/a'):\n",
    "        links1.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links1.append(\"-\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating1=[]\n",
    "Review1=[]\n",
    "Review_title1=[]\n",
    "for url in links1:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_xpath('//a[@class=\"all-review-btn\"]')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        \n",
    "        dropdown = driver.find_element_by_xpath('//*[@id=\"js-pd-scroll-start\"]/div[1]/div[2]/section/div/div')\n",
    "        negative = driver.find_element_by_xpath('//*[@id=\"js-pd-scroll-start\"]/div[1]/div[2]/section/div/div/span')\n",
    "        action= ActionChains(driver)\n",
    "        action.move_to_element(dropdown).move_to_element(negative).click().perform()\n",
    "        \n",
    "            # Extracting stars\n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"desc-section\"]/div[1]/div[1]')  \n",
    "            for r in rating:\n",
    "                Rating1.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating1.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"review-details\"]/section/p')   \n",
    "            for r in review:\n",
    "                Review1.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review1.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//div[@class=\"review-details\"]/section/h4')  \n",
    "            for r in review_title:\n",
    "                Review_title1.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title1.append('-')\n",
    "    except TimeoutException:\n",
    "        pass        \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of lists \n",
    "dict = {'Rating': Rating1, 'Review': Review1, 'Review_title': Review_title1} \n",
    "     \n",
    "df = pd.DataFrame(dict)\n",
    "  \n",
    "# saving the dataframe\n",
    "df.to_csv('Nykaa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapdeal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=['Headphones', 'Phones', 'smart watches', 'Monitors', 'Home theater', 'Router']\n",
    "links2=[]\n",
    "for i in items:\n",
    "    \n",
    "      # Opening the homepage of snapdeal\n",
    "    url = \"https://www.snapdeal.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    search_bar = driver.find_element_by_xpath('//*[@id=\"inputValEnter\"]')    # Finding the search bar using it's xpath\n",
    "    search_bar.clear()                                             # clearing search_bar\n",
    "    search_bar.send_keys(i)                                   # sending user input to search bar\n",
    "    search_button = driver.find_element_by_xpath('//*[@id=\"sdHeader\"]/div[4]/div[2]/div/div[2]/button')       # Locating search_button by xpath\n",
    "    search_button.click()  \n",
    "    \n",
    "    try:\n",
    "        for l in driver.find_elements_by_xpath('//a[@class=\"dp-widget-link noUdLine hashAdded\"]'):\n",
    "            links2.append(l.get_attribute('href'))\n",
    "            time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "            links2.append(\"-\")\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating2=[]\n",
    "Review2=[]\n",
    "Review_title2=[]\n",
    "for url in links2:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "        # Extracting stars\n",
    "    try:\n",
    "        rating = driver.find_elements_by_xpath('//div[@class=\"user-review\"]//div[@class=\"rating\"]')  \n",
    "        for r in rating:\n",
    "            child= r.find_elements_by_tag_name(\"i\")\n",
    "            Rating2.append(len(child))\n",
    "    except NoSuchElementException:\n",
    "        Rating2.append('-')\n",
    "\n",
    "    time.sleep(1)\n",
    "    # Extracting review\n",
    "    try:\n",
    "        review = driver.find_elements_by_xpath('//div[@class=\"commentreview\"]/div/div[2]/div[2]')   \n",
    "        for r in review:\n",
    "            Review2.append(r.text)\n",
    "    except NoSuchElementException:\n",
    "        Review2.append('-')\n",
    "\n",
    "    time.sleep(1)\n",
    "    # Extracting review\n",
    "    try:\n",
    "        review_title = driver.find_elements_by_xpath('//div[@class=\"commentreview\"]/div/div[2]/div[1]/div[2]')  \n",
    "        for r in review_title:\n",
    "            Review_title2.append(r.text)\n",
    "    except NoSuchElementException:\n",
    "        Review_title2.append('-')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of lists \n",
    "dict2 = {'Rating': Rating2, 'Review': Review2, 'Review_title': Review_title2} \n",
    "     \n",
    "df = pd.DataFrame(dict2)\n",
    "  \n",
    "# saving the dataframe\n",
    "df.to_csv('Snapdeal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipkart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\SAGAR KADAM\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "try:\n",
    "    search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "    search_bar.clear()                                             # clearing search_bar\n",
    "    search_bar.send_keys('laptops')                                   # sending user input to search bar\n",
    "    search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "    search_button.click()  \n",
    "except NoSuchElementException:\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "            time.sleep(2)\n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review=[]\n",
    "Review_title=[]\n",
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"NEGATIVE_FIRST\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Headphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\SAGAR KADAM\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Headphones')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "\n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        #action= ActionChains(driver)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Phones')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* smart watches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('smart watches')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "\n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "            \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Professional Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Login page\n"
     ]
    }
   ],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Professional Cameras')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "            \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Printers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Login page\n"
     ]
    }
   ],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Printers')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "\n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "            \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Monitors')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "            \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of lists \n",
    "dict3 = {'Rating': Rating, 'Review': Review, 'Review_title': Review_title} \n",
    "     \n",
    "df = pd.DataFrame(dict3)\n",
    "  \n",
    "# saving the dataframe\n",
    "df.to_csv('Flipkart1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Home theater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\SAGAR KADAM\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Home theater')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "            \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review=[]\n",
    "Review_title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "            driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "            driver.get(driver.current_url)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Login page\n"
     ]
    }
   ],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('Router')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"s1Q9rs\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Television"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Login page\n"
     ]
    }
   ],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('TV')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('AC')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Login page\n"
     ]
    }
   ],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('fridge')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* washing machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Login page\n"
     ]
    }
   ],
   "source": [
    "# Opening the homepage of flipkart\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "try:\n",
    "    login_X_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') # Button to close login popup\n",
    "    login_X_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')    # Finding the search bar using it's xpath\n",
    "search_bar.clear()                                             # clearing search_bar\n",
    "search_bar.send_keys('washing machines')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')       # Locating search_button by xpath\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "for page in range(0,10):\n",
    "        nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        try:\n",
    "            driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "        except:\n",
    "            driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        try:\n",
    "            for l in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "                links.append(l.get_attribute('href'))\n",
    "                time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "                links.append(\"-\")\n",
    "                time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        all_reviews = driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div/select').click()\n",
    "        driver.find_element_by_xpath('//select[@class=\"_1EDlbo tVKh2S\"]/option[@value=\"MOST_RECENT\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "        \n",
    "            \n",
    "        # Extracting stars      \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[1]/div[1]') \n",
    "            for r in rating:\n",
    "                Rating.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "        except StaleElementReferenceException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]/div/div') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')  \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of lists \n",
    "dict4 = {'Rating': Rating, 'Review': Review, 'Review_title': Review_title} \n",
    "     \n",
    "df = pd.DataFrame(dict4)\n",
    "  \n",
    "# saving the dataframe\n",
    "df.to_csv('Flipkart2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\SAGAR KADAM\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of Amazon.in\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('TV')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input')       # Locating search_button by xpath\n",
    "search_button.click()  \n",
    "links=[] \n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]'):\n",
    "        links.append(l.get_attribute('href'))\n",
    "        time.sleep(1)\n",
    "except NoSuchElementException:\n",
    "        links.append(\"-\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review=[]\n",
    "Review_title=[]\n",
    "for url in links:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_xpath('//*[@id=\"reviews-medley-footer\"]/div[2]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"a-autoid-6-announce\"]').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"star-count-dropdown_4\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "             # Extracting stars        \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//i[@data-hook=\"review-star-rating\"]/span')\n",
    "            for r in rating:\n",
    "                Rating.append(2)\n",
    "        except NoSuchElementException:\n",
    "            Rating.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"a-section celwidget\"]/div[4]') \n",
    "            for r in review:\n",
    "                Review.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//a[@data-hook=\"review-title\"]/span')      \n",
    "            for r in review_title:\n",
    "                Review_title.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title.append('-')\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Headphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of Amazon.in\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('Headphones')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input')       # Locating search_button by xpath\n",
    "search_button.click() \n",
    "links2=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]'):\n",
    "        links2.append(l.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    links2.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating2=[]\n",
    "Review2=[]\n",
    "Review_title2=[]\n",
    "for url in links2:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_xpath('//*[@id=\"reviews-medley-footer\"]/div[2]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"a-autoid-6-announce\"]').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"star-count-dropdown_4\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "             # Extracting stars        \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//i[@data-hook=\"review-star-rating\"]/span')\n",
    "            for r in rating:\n",
    "                Rating2.append(2)\n",
    "        except NoSuchElementException:\n",
    "            Rating2.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"a-section celwidget\"]/div[4]') \n",
    "            for r in review:\n",
    "                Review2.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review2.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//a[@data-hook=\"review-title\"]/span')      \n",
    "            for r in review_title:\n",
    "                Review_title2.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title2.append('-')\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of Amazon.in\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('Phones')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input')       # Locating search_button by xpath\n",
    "search_button.click() \n",
    "links3=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]'):\n",
    "        links3.append(l.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    links3.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating3=[]\n",
    "Review3=[]\n",
    "Review_title3=[]\n",
    "for url in links3:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_xpath('//*[@id=\"reviews-medley-footer\"]/div[2]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"a-autoid-6-announce\"]').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"star-count-dropdown_4\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "             # Extracting stars        \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//i[@data-hook=\"review-star-rating\"]/span')\n",
    "            for r in rating:\n",
    "                Rating3.append(2)\n",
    "        except NoSuchElementException:\n",
    "            Rating3.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"a-section celwidget\"]/div[4]') \n",
    "            for r in review:\n",
    "                Review3.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review3.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//a[@data-hook=\"review-title\"]/span')      \n",
    "            for r in review_title:\n",
    "                Review_title3.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title3.append('-')\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* smart watches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of Amazon.in\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('smart watches')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input')       # Locating search_button by xpath\n",
    "search_button.click() \n",
    "links4=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]'):\n",
    "        links4.append(l.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    links4.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating4=[]\n",
    "Review4=[]\n",
    "Review_title4=[]\n",
    "for url in links4:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_xpath('//*[@id=\"reviews-medley-footer\"]/div[2]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"a-autoid-6-announce\"]').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"star-count-dropdown_4\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "             # Extracting stars        \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//i[@data-hook=\"review-star-rating\"]/span')\n",
    "            for r in rating:\n",
    "                Rating4.append(2)\n",
    "        except NoSuchElementException:\n",
    "            Rating4.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"a-section celwidget\"]/div[4]') \n",
    "            for r in review:\n",
    "                Review4.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review4.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//a[@data-hook=\"review-title\"]/span')      \n",
    "            for r in review_title:\n",
    "                Review_title4.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title4.append('-')\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Home theater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of Amazon.in\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys('Home theater')                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]/span/input')       # Locating search_button by xpath\n",
    "search_button.click() \n",
    "links6=[]\n",
    "try:\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]'):\n",
    "        links6.append(l.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    links6.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating6=[]\n",
    "Review6=[]\n",
    "Review_title6=[]\n",
    "for url in links6:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_xpath('//*[@id=\"reviews-medley-footer\"]/div[2]/a')\n",
    "        a =all_reviews.get_attribute('href')\n",
    "        driver.get(a)\n",
    "        driver.find_element_by_xpath('//*[@id=\"a-autoid-6-announce\"]').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"star-count-dropdown_4\"]').click()\n",
    "        driver.get(driver.current_url)\n",
    "             # Extracting stars        \n",
    "        try:\n",
    "            rating = driver.find_elements_by_xpath('//i[@data-hook=\"review-star-rating\"]/span')\n",
    "            for r in rating:\n",
    "                Rating6.append(2)\n",
    "        except NoSuchElementException:\n",
    "            Rating6.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review = driver.find_elements_by_xpath('//div[@class=\"a-section celwidget\"]/div[4]') \n",
    "            for r in review:\n",
    "                Review6.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review6.append('-')\n",
    "\n",
    "        time.sleep(1)\n",
    "        # Extracting review\n",
    "        try:\n",
    "            review_title = driver.find_elements_by_xpath('//a[@data-hook=\"review-title\"]/span')      \n",
    "            for r in review_title:\n",
    "                Review_title6.append(r.text)\n",
    "        except NoSuchElementException:\n",
    "            Review_title6.append('-')\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_R= Rating + Rating2 + Rating3 + Rating4 + Rating6\n",
    "len(total_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_Re= Review + Review2 + Review3 + Review4 + Review6\n",
    "len(total_Re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Review_title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_Rt= Review_title + Review_title2 + Review_title3 + Review_title4 + Review_title6\n",
    "len(total_Rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of lists \n",
    "dict5 = {'Rating': total_R, 'Review': total_Re, 'Review_title': total_Rt} \n",
    "     \n",
    "df = pd.DataFrame(dict5)\n",
    "  \n",
    "# saving the dataframe\n",
    "df.to_csv('Amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=['Nykaa.csv', 'Snapdeal.csv','Flipkart1.csv','Flipkart2.csv','Amazon.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = pd.concat([pd.read_csv(f) for f in filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.to_excel( \"Rating.xlsx\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.to_excel( \"Rating_combined.xlsx\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
